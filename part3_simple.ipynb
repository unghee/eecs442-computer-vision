{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part3-simple.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unghee/eecs442-computer-vision/blob/master/part3_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zs_mu_Btw_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import png\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from colormap.colors import Color, hex2rgb\n",
        "from sklearn.metrics import average_precision_score as ap_score\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from dataset import FacadeDataset\n",
        "\n",
        "N_CLASS=5\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.n_class = N_CLASS\n",
        "        # self.layers = nn.Sequential(\n",
        "        #     #########################################\n",
        "        #     ###        TODO: Add more layers      ###\n",
        "        #     #########################################\n",
        "        #     # nn.Conv2d(3, self.n_class, 1, padding=0),\n",
        "        #     # nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # )\n",
        "\n",
        "\n",
        "        # self.down1=nn.Sequential(\n",
        "        self.conv0= nn.Conv2d(3, 64, 3, padding=1)\n",
        "\n",
        "        # down 1\n",
        "        self.pool1=nn.MaxPool2d(2)\n",
        "        self.conv1=nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.batchnorm1 =  nn.BatchNorm2d(128)\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "        # down 2\n",
        "        self.pool2=nn.MaxPool2d(2)\n",
        "        self.conv2=nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.batchnorm2 =  nn.BatchNorm2d(128)\n",
        "        self.relu=nn.ReLU()    \n",
        "\n",
        "        # )\n",
        "\n",
        "        # up 1\n",
        "        self.up1=nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        # self.conv3 = nn.Conv2d(192, 128, 3, padding=1)\n",
        "        self.conv_up1 = nn.Conv2d(256, 64, 3, padding=1)\n",
        "\n",
        "        # up 2\n",
        "        self.up2=nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv_up2 = nn.Conv2d(128, 64, 3, padding=1)\n",
        "        self.outconv=nn.Conv2d(64, self.n_class, kernel_size=3, padding=1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.layers(x)\n",
        "        x0 = self.conv0(x) # torch.Size([1, 64, 256, 256])\n",
        "\n",
        "        # down1\n",
        "        x1 = self.pool1(x0)\n",
        "        x1 = self.conv1(x1)\n",
        "        x1 = self.batchnorm1(x1)\n",
        "        x1 = self.relu(x1) # torch.Size([1, 128, 128, 128])\n",
        "  \n",
        "        # down2\n",
        "        x2 = self.pool2(x1) #torch.Size([1, 128, 64, 64])\n",
        "        x2 = self.conv2(x2) #torch.Size([1, 128, 64, 64])\n",
        "        x2 = self.batchnorm2(x2)\n",
        "        x2 = self.relu(x2)\n",
        "\n",
        "        # up1\n",
        "        x = self.up1(x2) #torch.Size([1, 128, 128, 128])\n",
        "        x = torch.cat([x,x1],dim=1) #torch.Size([1, 256, 128, 128])\n",
        "        x = self.conv_up1 (x) #torch.Size([1, 64, 128, 128])\n",
        "\n",
        "        # up2\n",
        "        x = self.up2(x) #torch.Size([1, 64, 256, 256])\n",
        "        x = torch.cat([x,x0],dim=1) #torch.Size([1, 128, 256, 256])\n",
        "        x = self.conv_up2(x)\n",
        "\n",
        "        logit = self.outconv(x)\n",
        "\n",
        "\n",
        "        # x1cs= self.up1(x1c)\n",
        "        # x2 = torch.cat([x0,x1cs],dim=1)\n",
        "        # x3 = self.conv3(x2)\n",
        "        # x4 = self.outconv(x3)\n",
        "\n",
        "\n",
        "        return logit\n",
        "\n",
        "\n",
        "def save_label(label, path):\n",
        "    '''\n",
        "    Function for ploting labels.\n",
        "    '''\n",
        "    colormap = [\n",
        "        '#000000',\n",
        "        '#0080FF',\n",
        "        '#80FF80',\n",
        "        '#FF8000',\n",
        "        '#FF0000',\n",
        "    ]\n",
        "    assert(np.max(label)<len(colormap))\n",
        "    colors = [hex2rgb(color, normalise=False) for color in colormap]\n",
        "    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)\n",
        "    with open(path, 'wb') as f:\n",
        "        w.write(f, label)\n",
        "\n",
        "def train(trainloader, net, criterion, optimizer, device, epoch):\n",
        "    '''\n",
        "    Function for training.\n",
        "    '''\n",
        "    start = time.time()\n",
        "    running_loss = 0.0\n",
        "    net = net.train()\n",
        "    for images, labels in tqdm(trainloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss = loss.item()\n",
        "    end = time.time()\n",
        "    print('[epoch %d] loss: %.3f elapsed time %.3f' %\n",
        "          (epoch, running_loss, end-start))\n",
        "\n",
        "def test(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Function for testing.\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        for images, labels in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)\n",
        "            loss = criterion(output, labels)\n",
        "            losses += loss.item()\n",
        "            cnt += 1\n",
        "    print(losses / cnt)\n",
        "    return (losses/cnt)\n",
        "\n",
        "\n",
        "def cal_AP(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Calculate Average Precision\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        preds = [[] for _ in range(5)]\n",
        "        heatmaps = [[] for _ in range(5)]\n",
        "        for images, labels in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images).cpu().numpy()\n",
        "            for c in range(5):\n",
        "                preds[c].append(output[:, c].reshape(-1))\n",
        "                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))\n",
        "\n",
        "        aps = []\n",
        "        for c in range(5):\n",
        "            preds[c] = np.concatenate(preds[c])\n",
        "            heatmaps[c] = np.concatenate(heatmaps[c])\n",
        "            if heatmaps[c].max() == 0:\n",
        "                ap = float('nan')\n",
        "            else:\n",
        "                ap = ap_score(heatmaps[c], preds[c])\n",
        "                aps.append(ap)\n",
        "            print(\"AP = {}\".format(ap))\n",
        "\n",
        "    # print(losses / cnt)\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_result(testloader, net, device, folder='output_train'):\n",
        "    result = []\n",
        "    cnt = 1\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        cnt = 0\n",
        "        for images, labels in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)[0].cpu().numpy()\n",
        "            c, h, w = output.shape\n",
        "            assert(c == N_CLASS)\n",
        "            y = np.zeros((h,w)).astype('uint8')\n",
        "            for i in range(N_CLASS):\n",
        "                mask = output[i]>0.5\n",
        "                y[mask] = i\n",
        "            gt = labels.cpu().data.numpy().squeeze(0).astype('uint8')\n",
        "            save_label(y, './{}/y{}.png'.format(folder, cnt))\n",
        "            save_label(gt, './{}/gt{}.png'.format(folder, cnt))\n",
        "            plt.imsave(\n",
        "                './{}/x{}.png'.format(folder, cnt),\n",
        "                ((images[0].cpu().data.numpy()+1)*128).astype(np.uint8).transpose(1,2,0))\n",
        "\n",
        "            cnt += 1\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # TODO change data_range to include all train/evaluation/test data.\n",
        "    # TODO adjust batch_size.\n",
        "    train_data = FacadeDataset(flag='train', data_range=(0,20), onehot=False)\n",
        "    train_loader = DataLoader(train_data, batch_size=1)\n",
        "    test_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=False)\n",
        "    test_loader = DataLoader(test_data, batch_size=1)\n",
        "    ap_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=True)\n",
        "    ap_loader = DataLoader(ap_data, batch_size=1)\n",
        "\n",
        "    name = 'starter_net'\n",
        "    net = Net().to(device)\n",
        "    criterion = nn.CrossEntropyLoss() #TODO decide loss\n",
        "    optimizer = torch.optim.Adam(net.parameters(), 1e-3, weight_decay=1e-5)\n",
        "    \n",
        "    test(train_loader, net, criterion, device)\n",
        "    print('\\nStart training')\n",
        "    for epoch in range(10): #TODO decide epochs\n",
        "        print('-----------------Epoch = %d-----------------' % (epoch+1))\n",
        "        train(train_loader, net, criterion, optimizer, device, epoch+1)\n",
        "        # TODO create your evaluation set, load the evaluation set and test on evaluation set\n",
        "        evaluation_loader = train_loader\n",
        "        test(evaluation_loader, net, criterion, device)\n",
        "\n",
        "    print('\\nFinished Training, Testing on test set')\n",
        "    test(test_loader, net, criterion, device)\n",
        "    print('\\nGenerating Unlabeled Result')\n",
        "    result = get_result(test_loader, net, device, folder='output_test')\n",
        "\n",
        "    torch.save(net.state_dict(), './models/model_{}.pth'.format(name))\n",
        "\n",
        "    cal_AP(ap_loader, net, criterion, device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}